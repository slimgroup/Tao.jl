var documenterSearchIndex = {"docs":
[{"location":"examples/3D_DFFT/#Distributed-FFT-of-a-3D-Tensor","page":"Distributed 3D FFT","title":"Distributed FFT of a 3D Tensor","text":"","category":"section"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"note: Jump right in\nTo get started, you can run some examples","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"Make sure to add necessary dependencies. You might also need to load a proper MPI implementation based on your hardware.","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"julia> ]\n(v1.9) activate /path/to/your/environment\n(env) add MPI CUDA ParametricOperators","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"warning: To run on multiple GPUs\nIf you wish to run on multiple GPUs, make sure the GPUs are binded to different tasks. The approach we use is to unbind our GPUs on request and assign manually:CUDA.device!(rank % 4)which might be different if you have more or less than 4 GPUs per node. Also, make sure your MPI distribution is functional.","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"using ParametricOperators\nusing CUDA\nusing MPI\n\nMPI.Init()\n\ncomm = MPI.COMM_WORLD\nrank = MPI.Comm_rank(comm)\nsize = MPI.Comm_size(comm)\n\n# Julia requires you to manually assign the gpus, modify to your case.\nCUDA.device!(rank % 4)\npartition = [1, 1, size]\n\nT = Float32\n\n# Define your Global Size and Data Partition\ngt, gx, gy = 100, 100, 100\nnt, nx, ny = [gt, gx, gy] .÷ partition\n\n# Define a transform along each dimension\nFt = ParDFT(T, gt)\nFx = ParDFT(Complex{T}, gx)\nFy = ParDFT(Complex{T}, gy)\n\n# Create and distribute the Kronecker operator than chains together the transforms\nF = Fy ⊗ Fx ⊗ Ft\nF = distribute(F, partition)\n\n# Apply the transform on a random input\nx = rand(T, nt, nx, ny) |> gpu\ny = F * vec(x)\n\nMPI.Finalize()","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"If you have mpiexecjl set up, you can run the above by doing:","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"mpiexecjl --project=/path/to/your/environment -n NTASKS julia code_above.jl","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"OR if you have a HPC cluster with slurm set up, you can do:","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"salloc --gpus=NTASKS --time=01:00:00 --ntasks=NTASKS --gpus-per-task=1 --gpu-bind=none\nsrun julia --project=/path/to/your/environment code_above.jl","category":"page"},{"location":"examples/3D_DFFT/","page":"Distributed 3D FFT","title":"Distributed 3D FFT","text":"warning: Allocation\nYour salloc might look different based on your HPC cluster","category":"page"},{"location":"distribution/#Distribution-as-Linear-Algebra","page":"Distribution","title":"Distribution as Linear Algebra","text":"","category":"section"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"We adapt an approach of looking at distribution of tensor computation as Linear Algebra operations. ","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"This allows ParametricOperators.jl to offer several high level API in order to perform controlled parallelism as part of your tensor program in the context of machine learning.","category":"page"},{"location":"distribution/#Kronecker-Distribution","page":"Distribution","title":"Kronecker Distribution","text":"","category":"section"},{"location":"distribution/#Distributed-Fourier-Transform","page":"Distribution","title":"Distributed Fourier Transform","text":"","category":"section"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Let's consider the example of Fourier Transform as seen in the Fourier Transform Example ","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"# Define type and the size of our global tensor\nT = Float32\ngx, gy, gz = 10, 20, 30\n\nFx = ParDFT(T, gx)\nFy = ParDFT(Complex{T}, gy)\nFz = ParDFT(Complex{T}, gz)\n\nF = Fz ⊗ Fy ⊗ Fx","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Assume that our data is partitioned across multiple machine according to the following scheme:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"partition = [1, 1, 2]","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Each element of partition denotes the number of processing elements that divide our input tensor along that dimension.","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"For eg. given the above partition and global size, our local tensor would be of size:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"x = rand(T, 10, 20, 15)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"OR in other terms:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"localx, localy, localz = [gx, gy, gz] .÷ partition\nx = rand(T, localx, localy, localz)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Now, following the method seen in several recent works (Grady et al., 2022) and traditional distributed FFTs, we can distribute the application of our linearly separable transform across multiple processing elements by simply doing:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"F = distribute(F, partition)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Now, to apply the Fourier Transform to our tensor, one can do:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"F * vec(x)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Another out-of-box example can be seen at Distributed FFT of a 3D Tensor","category":"page"},{"location":"distribution/#Distributed-Convolution","page":"Distribution","title":"Distributed Convolution","text":"","category":"section"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"note: Definition of Convolution\nConvolution here refers to the application of a linear transform along the channel dimension","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Now, in order to extend this to a convolution layer, lets consider the following partitioned tensor:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"T = Float32\n\ngx, gy, gc = 10, 30, 50\npartition = [2, 2, 1]\n\nnx, ny, nc = [gx, gy, gc] .÷ partition\nx = rand(T, nx, ny, nc)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Our tensor is sharded across x and y dimensions by 2 processing element along each dimension. ","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"We can define the operators of our convolution as:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Sx = ParIdentity(T, gx)\nSy = ParIdentity(T, gy)\nSc = ParMatrix(T, gc, gc)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Chain our operators and distribute them:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"S = Sc ⊗ Sy ⊗ Sx\nS = distribute(S, partition)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Parametrize and apply our transform:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"θ = init(S)\nS(θ) * vec(x)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Take the gradient of the parameters w.r.t to some objective by simply doing:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"θ′ = gradient(θ -> sum(S(θ) * vec(x)), θ)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Another out-of-box example can be seen at Distributed Parametrized Convolution of a 3D Tensor","category":"page"},{"location":"distribution/#Sharing-Weights","page":"Distribution","title":"Sharing Weights","text":"","category":"section"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Sharing weights can be thought of as a broadcasting operation.","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"In order to share weights of an operator across multiple processing elements, we can do:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"A = ParMatrix(T, 20, 20)\nA = distribute(A)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Assume the following partition and tensor shape:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"gc, gx = 20, 100\npartition = [1, 4]\n\nnc, nx = [gc, gx] .÷ partition\nx = rand(T, nc, nx)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Initialize and apply the matrix operator on the sharded tensor:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"θ = init(A)\nA(θ) * x","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Compute the gradient by doing:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"θ′ = gradient(θ -> sum(A(θ) * x), θ)","category":"page"},{"location":"distribution/#Reduction-Operation","page":"Distribution","title":"Reduction Operation","text":"","category":"section"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"In order to perform a reduction operation, more commonly known as an ALL_REDUCE operation, we can define:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"R = ParReduce(T)","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"Given any local vector or matrix, we can do:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"x = rand(T, 100)\nR * x","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"To compute the gradient of the input w.r.t some objective:","category":"page"},{"location":"distribution/","page":"Distribution","title":"Distribution","text":"x′ = gradient(x -> sum(R * x), x)","category":"page"},{"location":"examples/3D_Conv/#Parametrized-Convolution-on-3D-Tensor","page":"3D Conv","title":"Parametrized Convolution on 3D Tensor","text":"","category":"section"},{"location":"examples/3D_Conv/","page":"3D Conv","title":"3D Conv","text":"note: Jump right in\nTo get started, you can run some examples","category":"page"},{"location":"examples/3D_Conv/","page":"3D Conv","title":"3D Conv","text":"Make sure to add necessary dependencies to compute the gradient","category":"page"},{"location":"examples/3D_Conv/","page":"3D Conv","title":"3D Conv","text":"julia> ]\n(v1.9) activate /path/to/your/environment\n(env) Zygote ParametricOperators","category":"page"},{"location":"examples/3D_Conv/","page":"3D Conv","title":"3D Conv","text":"using ParametricOperators\nusing Zygote\n\nT = Float32\n\ngt, gx, gy = 100, 100, 100\n\n# Define a transform along each dimension\nSt = ParMatrix(T, gt, gt)\nSx = ParMatrix(T, gx, gx)\nSy = ParMatrix(T, gy, gy)\n\n# Create a Kronecker operator than chains together the transforms\nS = Sy ⊗ Sx ⊗ St\n\n# Parametrize our transform\nθ = init(S) |> gpu\n\n# Apply the transform on a random input\nx = rand(T, gt, gx, gy) |> gpu\ny = S(θ) * vec(x)\n\n# Compute the gradient wrt some objective of our parameters\nθ′ = gradient(θ -> sum(S(θ) * vec(x)), θ)","category":"page"},{"location":"examples/3D_Conv/","page":"3D Conv","title":"3D Conv","text":"Run the above by doing:","category":"page"},{"location":"examples/3D_Conv/","page":"3D Conv","title":"3D Conv","text":"julia --project=/path/to/your/environment code_above.jl","category":"page"},{"location":"api/#API-usage-for-different-operators","page":"API","title":"API usage for different operators","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Coming soon...","category":"page"},{"location":"examples/3D_DConv/#Distributed-Parametrized-Convolution-of-a-3D-Tensor","page":"Distributed 3D Conv","title":"Distributed Parametrized Convolution of a 3D Tensor","text":"","category":"section"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"note: Jump right in\nTo get started, you can run some examples","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"Make sure to add necessary dependencies. You might also need to load a proper MPI implementation based on your hardware.","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"julia> ]\n(v1.9) activate /path/to/your/environment\n(env) add MPI CUDA ParametricOperators","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"warning: To run on multiple GPUs\nIf you wish to run on multiple GPUs, make sure the GPUs are binded to different tasks. The approach we use is to unbind our GPUs on request and assign manually:CUDA.device!(rank % 4)which might be different if you have more or less than 4 GPUs per node. Also, make sure your MPI distribution is functional.","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"using ParametricOperators\nusing CUDA\nusing MPI\nusing Zygote\n\nMPI.Init()\n\ncomm = MPI.COMM_WORLD\nrank = MPI.Comm_rank(comm)\nsize = MPI.Comm_size(comm)\n\n# Julia requires you to manually assign the gpus, modify to your case.\nCUDA.device!(rank % 4)\npartition = [1, 1, size]\n\nT = Float32\n\n# Define your Global Size and Data Partition\ngt, gx, gy = 100, 100, 100\nnt, nx, ny = [gt, gx, gy] .÷ partition\n\n# Define a transform along each dimension\nSt = ParMatrix(T, gt, gt)\nSx = ParMatrix(T, gx, gx)\nSy = ParMatrix(T, gy, gy)\n\n# Create and distribute the Kronecker operator than chains together the transforms\nS = Sy ⊗ Sx ⊗ St\nS = distribute(S, partition)\n\n# Parametrize our transform\nθ = init(S) |> gpu\n\n# Apply the transform on a random input\nx = rand(T, nt, nx, ny) |> gpu\ny = S(θ) * vec(x)\n\n# Compute the gradient wrt some objective of our parameters\nθ′ = gradient(θ -> sum(S(θ) * vec(x)), θ)\n\nMPI.Finalize()","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"If you have mpiexecjl set up, you can run the above by doing:","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"mpiexecjl --project=/path/to/your/environment -n NTASKS julia code_above.jl","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"OR if you have a HPC cluster with slurm set up, you can do:","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"salloc --gpus=NTASKS --time=01:00:00 --ntasks=NTASKS --gpus-per-task=1 --gpu-bind=none\nsrun julia --project=/path/to/your/environment code_above.jl","category":"page"},{"location":"examples/3D_DConv/","page":"Distributed 3D Conv","title":"Distributed 3D Conv","text":"warning: Allocation\nYour salloc might look different based on your HPC cluster","category":"page"},{"location":"future/#Future-Work","page":"Future Work","title":"Future Work","text":"","category":"section"},{"location":"future/","page":"Future Work","title":"Future Work","text":"Minimize computation and communication costs over all transformations of the abstract syntax tree such that ","category":"page"},{"location":"future/","page":"Future Work","title":"Future Work","text":"the transformations follow mathematical rules.\nthe transformations keep compute and memory bounded to the specification of the system\nthe transformations give an optimal distribution pattern at a given point in the computation","category":"page"},{"location":"future/","page":"Future Work","title":"Future Work","text":"Add tensor-tensor contraction to the abstraction","category":"page"},{"location":"citation/#Citation","page":"Citation","title":"Citation","text":"","category":"section"},{"location":"citation/","page":"Citation","title":"Citation","text":"If you use ParametricOperators.jl, please cite the following:","category":"page"},{"location":"citation/","page":"Citation","title":"Citation","text":"@presentation {rex2023ML4SEISMIClsp,\n\ttitle = {Large-scale parametric PDE approximations with model-parallel Fourier neural operators},\n\tyear = {2023},\n\tmonth = {11},\n\turl = {https://slim.gatech.edu/Publications/Public/Conferences/ML4SEISMIC/2023/rex2023ML4SEISMIClsp},\n\tauthor = {Richard Rex and Thomas J. Grady II and Rishi Khan and Ziyi Yin and Felix J. Herrmann}\n}","category":"page"},{"location":"quickstart/#Installation","page":"Quick Start","title":"Installation","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Add ParametricOperators.jl as a dependency to your environment.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"To add, either do:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"julia> ]\n(v1.9) add ParametricOperators","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"OR","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"julia> using Pkg\njulia> Pkg.activate(\"path/to/your/environment\")\njulia> Pkg.add(\"ParametricOperators\")","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"note: Jump right in\nTo get started, you can also try running some examples","category":"page"},{"location":"quickstart/#Simple-Operator","page":"Quick Start","title":"Simple Operator","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Make sure to include the package in your environment","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"using ParametricOperators","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Lets start by defining a Matrix Operator of size 10x10:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"A = ParMatrix(10, 10)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Now, we parametrize our operator with some weights θ:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"θ = init(A)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We can now apply our operator on some random input:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"x = rand(10)\nA(θ) * x","category":"page"},{"location":"quickstart/#Gradient-Computation","page":"Quick Start","title":"Gradient Computation","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"warning: Limited AD support\nCurrent support only provided for Zygote.jl","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Make sure to include an AD package in your environment","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"using Zygote","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Using the example above, one can find the gradient of the weights or your input w.r.t to some objective using a standard AD package:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"# Gradient w.r.t weights\nθ′ = gradient(θ -> sum(A(θ) * x), θ)\n\n# Gradient w.r.t input\nx′ = gradient(x -> sum(A(θ) * x), x)","category":"page"},{"location":"quickstart/#Chaining-Operators","page":"Quick Start","title":"Chaining Operators","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We can chain several operators together through multiple ways ","category":"page"},{"location":"quickstart/#Compose-Operator","page":"Quick Start","title":"Compose Operator","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Consider two matrices:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"L = ParMatrix(10, 4)\nR = ParMatrix(10, 4)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We can now chain and parametrize them by:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"C = L * R'\nθ = init(C)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"This allows us to perform several operations such as","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"\nusing Zygote\nusing LinearAlgebra\n\nx = rand(10)\nC(θ) * x\ngradient(θ -> norm(C(θ) * x), θ)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"without ever constructing the full matrix LR', a method more popularly referred to as LR-decomposition.","category":"page"},{"location":"quickstart/#Kronecker-Operator","page":"Quick Start","title":"Kronecker Operator","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Kronecker Product is a most commonly used to represent the outer product on 2 matrices.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We can use this to describe linearly separable transforms that act along different dimensions on a given input tensor.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"For example, consider the following tensor:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"T = Float32\nx = rand(T, 10, 20, 30)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We now define the transformation that would act along each dimension. In this case, a Fourier Transform.","category":"page"},{"location":"quickstart/#Fourier-Transform-Example","page":"Quick Start","title":"Fourier Transform Example","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Fx = ParDFT(T, 10)\nFy = ParDFT(Complex{T}, 20)\nFz = ParDFT(Complex{T}, 30)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We can now chain them together using a Kronecker Product:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"F = Fz ⊗ Fy ⊗ Fx","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Now, we can compute this action on our input by simply doing:","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"F * vec(x)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"tip: This can be extended to any parametrized operators\nFor example, in order to apply a linear transform along the y, z dimension while performing no operation along x, one can do:    Sx = ParIdentity(T, 10)\n    Sy = ParMatrix(T, 20, 20)\n    Sz = ParMatrix(T, 30, 30)\n\n    S = Sz ⊗ Sy ⊗Sx\n    θ = init(S)\n\n    S(θ) * vec(x)","category":"page"},{"location":"examples/#ParametricOperators.jl","page":"ParametricOperators.jl","title":"ParametricOperators.jl","text":"","category":"section"},{"location":"examples/","page":"ParametricOperators.jl","title":"ParametricOperators.jl","text":"Documentation for ParametricOperators.jl","category":"page"},{"location":"examples/3D_FFT/#FFT-of-3D-Tensor","page":"3D FFT","title":"FFT of 3D Tensor","text":"","category":"section"},{"location":"examples/3D_FFT/","page":"3D FFT","title":"3D FFT","text":"note: Jump right in\nTo get started, you can run some examples","category":"page"},{"location":"examples/3D_FFT/","page":"3D FFT","title":"3D FFT","text":"using ParametricOperators\n\nT = Float32\n\ngt, gx, gy = 100, 100, 100\n\n# Define a transform along each dimension\nFt = ParDFT(T, gt)\nFx = ParDFT(Complex{T}, gx)\nFy = ParDFT(Complex{T}, gy)\n\n# Create a Kronecker operator than chains together the transforms\nF = Fy ⊗ Fx ⊗ Ft\n\n# Apply the transform on a random input\nx = rand(T, gt, gx, gy) |> gpu\ny = F * vec(x)","category":"page"},{"location":"examples/3D_FFT/","page":"3D FFT","title":"3D FFT","text":"Run the above by doing:","category":"page"},{"location":"examples/3D_FFT/","page":"3D FFT","title":"3D FFT","text":"julia --project=/path/to/your/environment code_above.jl","category":"page"},{"location":"#ParametricOperators.jl","page":"Introduction","title":"ParametricOperators.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Modern machine learning and scientific computing is increasingly interested in the idea of tensor programs, or programs where the fundamental object is the tensor: a multidimensional array of numbers.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"ParametricOperators.jl is an abstraction based on Kronecker products, designed for manipulating large scale tensors. It utilizes lazy operators to facilitate distribution and gradient computation effectively.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"note: Example usage of ParametricOperators.jl\nParametricDFNOs.jl is a library built on top of ParametricOperators.jl that allows for large scale machine learning using Fourier Neural Operators (FNOs)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Read our paper here.","category":"page"},{"location":"#Authors","page":"Introduction","title":"Authors","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This package is developed and maintained by Felix J. Herrmann's SlimGroup at Georgia Institute of Technology. The main contributors of this package are:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Richard Rex\nThomas Grady\nMark Gliens","category":"page"},{"location":"#License","page":"Introduction","title":"License","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"MIT License\n\nCopyright (c) 2024 SLIM Group @ Georgia Institute of Technology\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.","category":"page"}]
}
